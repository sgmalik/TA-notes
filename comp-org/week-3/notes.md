# Week 3: Basics of Computer Architecture  
*References: Patterson & Hennessy, ARM Edition, Chapter 1 (§1.1–§1.5)*  

---

## 1. Computer Architecture vs. Computer Organization (§1.1)  

When we talk about a computer’s design, it is important to separate two closely related but distinct ideas: **architecture** and **organization**.  

**Computer architecture** refers to the abstract model of the machine, the aspects that a programmer sees and interacts with. This includes the instruction set (the set of operations the computer can perform), the supported data types (integers, floating-point numbers, characters), the memory model, and the addressing modes. Architecture defines *what* the computer does, not *how* it is implemented.  

**Computer organization**, on the other hand, describes the actual implementation of the architecture in hardware. This includes details such as the datapath (the circuits that carry out operations), control logic, pipeline structure, and the arrangement of memory and caches. Organization concerns *how* the machine performs the operations defined by the architecture.  

To use an analogy, think of designing a house. The **blueprint** shows the layout of rooms, doors, and windows, this is the *architecture*. The choice of materials, the wiring behind the walls, and the plumbing details are the *organization*. Two houses with the same blueprint can be built in different ways, just as two CPUs with the same architecture can have different organizations.  

For example, the ARM architecture defines a particular instruction set. A simple ARM processor in a smartwatch and a powerful ARM-based processor in a smartphone both implement the same architecture, but their organizations differ drastically in clock speed, cache design, and power management.  

---

## 2. Major Components of a Computer System (§1.3)  

A modern computer system can be understood as four interacting parts: the **CPU**, **memory**, **I/O devices**, and the **buses** that connect them.  

The **CPU (Central Processing Unit)** is the “brain” of the computer. It has two primary subsystems: the **control unit**, which directs the flow of instructions and data, and the **datapath**, which contains the arithmetic and logic unit (ALU) and registers. The ALU carries out basic operations such as addition, subtraction, and comparisons, while registers provide very small but extremely fast storage locations inside the CPU.  

The **memory hierarchy** organizes storage in layers, balancing speed and size. At the very top are **registers**, which are the fastest but also the smallest in capacity. Just below that are **caches**, small amounts of fast memory located close to the CPU to reduce the delay of accessing frequently used data. The next level is **main memory (RAM)**, which is larger but slower. Finally, **secondary storage** such as solid-state drives (SSDs) or hard drives provides massive capacity but at much lower speeds. This hierarchy exists because it is physically and economically impossible to build a single large, fast, cheap memory. By combining levels, systems achieve both speed and capacity.  

**I/O (Input/Output) devices** are the way the computer interacts with the outside world. Input devices include keyboards, mice, and sensors. Output devices include monitors, speakers, and printers. Storage devices and networking equipment are also part of the I/O system.  

Finally, these components communicate via **buses**, which are shared communication pathways that carry data, memory addresses, and control signals. Modern systems often use multiple buses internally to manage communication bottlenecks.  

---

## 3. Stored-Program Concept & Von Neumann Model (§1.2)  

One of the most important breakthroughs in computing was the **stored-program concept**, proposed by John von Neumann and colleagues in 1945 in the design of the EDVAC computer. The idea was simple but transformative: both instructions and data should be stored together in the same memory. This allowed the CPU to fetch instructions sequentially and made programs flexible; programs could be modified, moved, or even generated by other programs, since they were simply data in memory.  

The **Von Neumann architecture** built on this concept. It describes a computer model in which a single memory holds both instructions and data, and the CPU executes instructions sequentially from that memory. This model underlies virtually all modern general-purpose computers.  

However, the Von Neumann model introduces a limitation known as the **Von Neumann bottleneck**. Because both instructions and data share the same memory and bus system, the CPU cannot fetch an instruction and read or write data at the same time. As CPUs became faster, memory access became the limiting factor in overall performance.  

Some systems instead use the **Harvard architecture**, where instructions and data are stored in separate memories with separate access paths. This eliminates the bottleneck but increases hardware complexity. Harvard architectures are common in embedded systems such as microcontrollers, where efficiency and predictability are more important than flexibility.  

---

## 4. The Fetch–Decode–Execute Cycle (§1.4)  

Every instruction executed by the CPU goes through a standard cycle known as the **fetch–decode–execute cycle**. This cycle describes how the CPU interprets and carries out instructions step by step.  

1. **Fetch**: The CPU retrieves the next instruction from memory. The address of this instruction is held in the **program counter (PC)**.  
2. **Decode**: The control unit examines the instruction to determine the operation (the opcode) and the operands (which data values or registers are involved).  
3. **Execute**: The datapath performs the required operation. For arithmetic instructions, the ALU carries out the calculation. For memory instructions, data may be loaded or stored.  
4. **Store**: If the instruction produces a result, it is written to a register or to memory.  
5. **Update PC**: The program counter is updated to point to the next instruction. In the case of a branch or jump, the PC may be set to a new address.  

As an example, consider an instruction that adds the contents of two registers, `R2` and `R3`, and stores the result in `R1`. The CPU fetches this instruction from memory, decodes it as an addition, executes the addition in the ALU, stores the sum in `R1`, and then increments the PC to fetch the next instruction.  

This cycle repeats continuously while the computer runs, forming the heartbeat of the CPU.  

---

## 5. RISC vs. CISC (Preview Only) (§1.1)  

Instruction sets come in two broad families: **RISC (Reduced Instruction Set Computer)** and **CISC (Complex Instruction Set Computer)**.  

**RISC architectures**, such as ARM, use a small set of simple instructions, each designed to execute quickly and usually in a single clock cycle. Instructions are fixed in length and follow a regular structure, which simplifies decoding and supports high-performance implementations like pipelining.  

**CISC architectures**, such as Intel’s x86, have large and varied instruction sets, with instructions that can perform complex operations. Instructions may vary in length, and some can execute multi-step operations in a single instruction. While this can make programs shorter, it complicates decoding and execution.  

Modern processors blur the line between RISC and CISC. For example, x86 processors often translate complex instructions internally into simpler micro-operations, similar to RISC instructions.  

For now, it is enough to understand that ARM is an example of RISC, and x86 is an example of CISC. The details of instruction sets will be covered later in the course.  

---

## 6. Basic Performance Metrics (§1.5)  

When comparing processors, it is tempting to look only at the clock speed in gigahertz (GHz). However, performance depends on multiple factors. The fundamental equation for CPU execution time is:  

```

CPU Time = Instruction Count × CPI × Clock Cycle Time

```

- **Instruction Count (IC):** The number of instructions executed by the program.  
- **CPI (Cycles Per Instruction):** The average number of clock cycles required for each instruction.  
- **Clock Cycle Time:** The duration of a single cycle, which is the inverse of the clock frequency.  

For example, consider two processors:  

- Processor A: 3 GHz clock, average CPI = 2  
- Processor B: 2 GHz clock, average CPI = 1.2  

Processor A has a clock cycle time of 0.333 ns. With a CPI of 2, each instruction takes 0.666 ns.  
Processor B has a cycle time of 0.5 ns. With a CPI of 1.2, each instruction takes 0.6 ns.  

Even though Processor A has a higher clock frequency, Processor B actually executes each instruction faster because of its lower CPI.  

This shows why GHz alone is not a good indicator of performance. Compiler optimizations, instruction set design, and microarchitecture all affect how many instructions are executed and how many cycles they take.  

---

## 7. Summary and Transition  

This week introduced the big-picture view of computer architecture. We distinguished **architecture** (the abstract model) from **organization** (the implementation). We reviewed the major components of a computer system: CPU, memory, I/O, and buses. We discussed the **stored-program concept** and the **Von Neumann model**, including the bottleneck that arises from shared memory. We then examined the **fetch–decode–execute cycle**, the fundamental loop by which CPUs operate. Finally, we previewed the distinction between **RISC** and **CISC** architectures and introduced the **CPU performance equation** as a way of comparing processors.  

Next week, we will turn from this high-level view to the building blocks of processors: **logic gates, combinational circuits, and sequential logic**. These components show how the abstract concepts of architecture are realized in physical hardware.  

